#These are used when processing the data into chunks by teh prep_docs script
CORPUS_RAW_FILE_DIR=/Users/jennifersawyer/dev/datasets/corpus_of_cthulhu/txts
CORPUS_JSONL_FILE=/Users/jennifersawyer/dev/datasets/corpus_of_cthulhu/chunks-bge_encode.jsonl

#ElasticSearch used by agent and when ingesting data
ES_HOST=https://localhost:30920
ES_USER=elastic
ES_PASSWORD=changeme
ES_INDEX=lovecraft_chunks


USE_OLLAMA=true
# The following variables only matter if you are on a Linux machine with GPU support and plan to not use ollama or 3rd parties
LLM_MODEL_DIR=/opt/eldritch_oracle/models/llama3
LLM_MODEL_FILE=Llama-3.2-3B-Instruct-Q4_K_M.gguf
LLM_MODEL_PATH=${LLM_MODEL_DIR}/${LLM_MODEL_FILE}
LLM_MODEL_URL=https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf

# These are used by the API to call the language server
INFERENCE_API_URL=http://localhost:11434/v1 # Ollama default.
INFERENCE_API_KEY=ollama  # dummy value for Ollama, real key for OpenAI or other OpenAI API compatible service. In production you should get rid of this and inject from your secret store.
INFERENCE_MODEL_NAME=llama3.2
